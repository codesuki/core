{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from collections import deque\n",
    "from time import time\n",
    "import datetime\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.rnn.python.ops.rnn_cell import PhasedLSTMCell\n",
    "from tensorflow.python.ops.rnn import dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# methods - mostly from training.py\n",
    "\n",
    "def compute_returns(close_prices):\n",
    "    close_prices_returns = pd.DataFrame(100 * ((close_prices.shift(-1) - close_prices) / close_prices).fillna(0.0))\n",
    "    return close_prices_returns.shift(1).fillna(0)\n",
    "\n",
    "\n",
    "def get_batch(bs, prices, sequence_length):\n",
    "    batch_x = []\n",
    "    batch_t = []\n",
    "    batch_y = []\n",
    "    for jj in range(bs):\n",
    "        start = np.random.choice(range(len(prices) - sequence_length - 1))\n",
    "        values = prices[start: start + sequence_length + 1].values\n",
    "        x = np.array(values[0:-1, 1], dtype=float)\n",
    "        y = np.array(values[-1, 1], dtype=float)\n",
    "        t = np.array(values[0:-1, 0], dtype=float)\n",
    "        batch_x.append(x)\n",
    "        batch_t.append(t)\n",
    "        batch_y.append(y)\n",
    "    return np.expand_dims(batch_x, axis=2), np.expand_dims(batch_t, axis=2), np.expand_dims(batch_y, axis=1)\n",
    "\n",
    "\n",
    "def run_training(hidden_size, batch_size, steps, num_layers=1, return_only_last_output=True):\n",
    "\n",
    "    ####################### MODEL PART #######################\n",
    "    sequence_length = 20  # for now let's do like this.\n",
    "    learning_rate = 1e-7\n",
    "    print('hidden_size:', hidden_size)\n",
    "    print('num_layers:', num_layers)\n",
    "    print('batch_size:', batch_size)\n",
    "    print('steps:', steps)\n",
    "    print('learning_rate:', learning_rate)\n",
    "    print('sequence_length:', sequence_length)\n",
    "\n",
    "    x_ = tf.placeholder(tf.float32, (batch_size, sequence_length, 1))\n",
    "    t_ = tf.placeholder(tf.float32, (batch_size, sequence_length, 1))\n",
    "    y_ = tf.placeholder(tf.float32, (batch_size, 1))\n",
    "\n",
    "    \n",
    "    # multi_lstm - combines training.py & models > model_helper.py\n",
    "    rnn_out = []\n",
    "    for i in range(num_layers):\n",
    "        x, _ = dynamic_rnn(cell=PhasedLSTMCell(hidden_size), inputs=(t_, x_), dtype=tf.float32, scope='LSTM_' + str(np.random.random_sample()))\n",
    "    if return_only_last_output == True:\n",
    "        rnn_out = tf.squeeze(x[:, -1, :])\n",
    "    else:\n",
    "        rnn_out = x        \n",
    "\n",
    "    out = slim.fully_connected(inputs=rnn_out,\n",
    "                               num_outputs=hidden_size,\n",
    "                               activation_fn=tf.nn.tanh)\n",
    "\n",
    "    out = slim.fully_connected(inputs=out,\n",
    "                               num_outputs=1,\n",
    "                               activation_fn=None)\n",
    "\n",
    "    print('*' * 80)\n",
    "    print('TRAINABLE VARIABLES')\n",
    "    for tv in tf.trainable_variables():\n",
    "        print(tv)\n",
    "    num_params = np.sum([np.prod([int(e) for e in d.shape.dims], axis=0) for d in tf.trainable_variables()])\n",
    "    print('TOTAL NUMBER OF TRAINABLE VARIABLES = {}'.format(num_params))\n",
    "    print('*' * 80)\n",
    "\n",
    "    loss = 100 * tf.reduce_mean(tf.abs(out - y_))\n",
    "    benchmark_loss = 100 * tf.reduce_mean(tf.abs(y_))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)  # clip please.\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    ####################### DATA PART #######################\n",
    "    # removing the columns where the last price did not move. It biases the model.\n",
    "    prices = read_price_data_example()\n",
    "    prices = prices[['timestamp', 'last']].astype(np.float)\n",
    "    prices['last'] = compute_returns(prices['last'])\n",
    "    prices = prices[prices['last'] != 0]\n",
    "\n",
    "    ####################### RUN PART #######################\n",
    "    running_difference = deque(maxlen=100)\n",
    "    running_accuracy = deque(maxlen=100)\n",
    "    for i in range(steps):\n",
    "        x_train, t_train, y_train = get_batch(batch_size, prices, sequence_length)\n",
    "        st = time()\n",
    "        sess.run([train_step], feed_dict={x_: x_train, y_: y_train, t_: t_train})  # gradient update.\n",
    "\n",
    "        x_test, t_test, y_test = get_batch(batch_size, prices, sequence_length)\n",
    "        te_loss, be_loss = sess.run([loss, benchmark_loss],\n",
    "                                    feed_dict={x_: x_test, y_: y_test, t_: t_test})\n",
    "        running_difference.append(be_loss - te_loss)\n",
    "        running_accuracy.append(te_loss < be_loss)\n",
    "        print(\n",
    "            'steps = {0} | time {1:.3f} | te_loss = {2:.6f}, be_loss = {3:.6f}, r_diff = {4:.6f}, r_acc = {5:.3f}'.format(\n",
    "                str(i).zfill(6), time() - st, te_loss, be_loss, np.mean(running_difference), np.mean(running_accuracy)))\n",
    "        \n",
    "# not used yet - from data > read_price_data.py\n",
    "def read_price_data():\n",
    "    \n",
    "    HEADERS = ['high', 'last', 'timestamp', 'bid', 'vwap', 'volume', 'low', 'ask', 'open']\n",
    "\n",
    "    np.set_printoptions(threshold=np.nan)\n",
    "    pd.set_option('display.height', 1000) # height has been deprecated\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n",
    "        \n",
    "    np_data = []\n",
    "    all_json = glob('bitstamp_record_price' + '/*.json')\n",
    "    print('Found {} prices updates.'.format(len(all_json)))\n",
    "    # bar = progressbar.ProgressBar()\n",
    "    for filename in all_json:\n",
    "        # print(filename)\n",
    "        try:\n",
    "            with open(filename, 'r') as r:\n",
    "                d = json.load(r)\n",
    "                l = []\n",
    "                for header in HEADERS:\n",
    "                    l.append(str(d[header]))\n",
    "            np_data.append(l)\n",
    "        except:\n",
    "            print('Problem with filename [{}].'.format(filename))\n",
    "\n",
    "    if len(np_data) == 0:\n",
    "        raise Exception('No data available in {}'.format(data_dir))\n",
    "\n",
    "    np_data = np.array(np_data)\n",
    "    d = pd.DataFrame(np_data, index=np_data[:, 2])\n",
    "    d.columns = HEADERS\n",
    "    d.index = d.index.map(lambda ts: datetime.datetime.fromtimestamp(int(ts)))\n",
    "    print('Data set has {} rows.'.format(len(d)))\n",
    "    d.drop_duplicates(inplace=True)\n",
    "    print('Removing duplicates...')\n",
    "    print('Data set has {} rows.'.format(len(d)))\n",
    "    d.index.names = ['DateTime_UTC']\n",
    "    d.to_csv(arg_p.output_file)\n",
    "    print(d)\n",
    "    return d\n",
    "\n",
    "# data actually used\n",
    "def read_price_data_example():\n",
    "    \n",
    "    d = pd.read_csv('../data_examples/btc_price_2017-09-13T03:45:28+00:00.csv')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "run_training(hidden_size=1024, batch_size=32, steps=10000, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
